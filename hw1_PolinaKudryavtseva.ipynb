{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1\n",
    "### –ö—É–¥—Ä—è–≤—Ü–µ–≤–æ–π –ü–æ–ª–∏–Ω—ã, –ë–ö–õ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ó–¥–µ—Å—å –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –º–æ–¥—É–ª—å –ø—Ä–æ–≤–µ—Ä–∫–∏ PEP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in /anaconda3/lib/python3.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: flake8 in /anaconda3/lib/python3.7/site-packages (3.7.8)\n",
      "Requirement already satisfied: pycodestyle_magic in /anaconda3/lib/python3.7/site-packages (0.4)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /anaconda3/lib/python3.7/site-packages (from flake8) (2.1.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /anaconda3/lib/python3.7/site-packages (from flake8) (0.6.1)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /anaconda3/lib/python3.7/site-packages (from flake8) (0.3)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "! pip3 install pycodestyle flake8 pycodestyle_magic\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) –°–∫–æ–ª—å–∫–æ —Ç–≤–∏—Ç–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = []\n",
    "for line in open('hw_3_twitter.json'):\n",
    "    twitter.append(json.loads(line))\n",
    "\n",
    "all_tweets = len(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í –Ω–∞–±–æ—Ä–µ 2556 —Ç–≤–∏—Ç–æ–≤.\n"
     ]
    }
   ],
   "source": [
    "print('–í –Ω–∞–±–æ—Ä–µ', all_tweets, '—Ç–≤–∏—Ç–æ–≤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) –ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ç–≤–∏—Ç–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç —É–¥–∞–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏?\n",
    "* –¢—ç–≥ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤ - 'delete'.\n",
    "* –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥ —Å–ª–æ–≤–∞—Ä–µ–π get, –∫–æ—Ç–æ—Ä—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –∫–ª—é—á—É.\n",
    "* –î–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å—á–µ—Ç—á–∏–∫ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_tweets = 0\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get(\"delete\") is not None:\n",
    "        deleted_tweets += 1\n",
    "\n",
    "percent_of_deleted = deleted_tweets * 100 / all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£–¥–∞–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç 14.162754303599375 %.\n",
      "–¢–æ –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ 14 %.\n"
     ]
    }
   ],
   "source": [
    "print('–£–¥–∞–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç', percent_of_deleted, '%.')\n",
    "print('–¢–æ –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ', round(percent_of_deleted), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) –ö–∞–∫–∏–µ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —è–∑—ã–∫–∏ —Ç–≤–∏—Ç–æ–≤?\n",
    "* –¢—ç–≥ —è–∑—ã–∫–∞ —Ç–≤–∏—Ç–æ–≤ - 'lang'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get('lang') is not None:\n",
    "        languages.append(tweet.get('lang'))\n",
    "\n",
    "counter_of_languages = Counter(languages)\n",
    "ten_top_languages = counter_of_languages.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —è–∑—ã–∫–æ–≤ —Ç–≤–∏—Ç–æ–≤:\n",
      "en\n",
      "ja\n",
      "es\n",
      "ko\n",
      "th\n",
      "ar\n",
      "und\n",
      "in\n",
      "pt\n",
      "fr\n"
     ]
    }
   ],
   "source": [
    "print('10 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —è–∑—ã–∫–æ–≤ —Ç–≤–∏—Ç–æ–≤:')\n",
    "for language in ten_top_languages:\n",
    "    the_language = language[0]\n",
    "    print(the_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) –ï—Å—Ç—å –ª–∏ —Ç–≤–∏—Ç—ã –æ—Ç –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è? –ï—Å–ª–∏ –¥–∞, —Ç–æ —Å–∫–æ–ª—å–∫–æ —Ç–∞–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π?\n",
    "* –í –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ json –≤ Twitter —Å–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å \"id_str\".\n",
    "* –í —Å–ø–∏—Å–∫–µ ids —Å–æ–±—Ä–∞–Ω—ã –≤—Å–µ id —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏.\n",
    "* –í —Å–ª–æ–≤–∞—Ä–µ repeating_authors –∑–∞–ø–∏—Å–∞–Ω—ã –≤—Å–µ id, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–≤—Ç–æ—Ä–∏–ª–∏—Å—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "repeating_authors = {}\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get('user') is not None:\n",
    "        id_str = tweet['user'].get('id_str')\n",
    "        ids.append(id_str)\n",
    "\n",
    "counter_of_id = Counter(ids)\n",
    "for key, value in counter_of_id.items():\n",
    "    if value > 1:\n",
    "        repeating_authors[key] = value\n",
    "\n",
    "authors = len(repeating_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —Ç–≤–∏—Ç–∏–ª–∏ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞, -  25 .\n"
     ]
    }
   ],
   "source": [
    "print('–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —Ç–≤–∏—Ç–∏–ª–∏ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞, - ', authors, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) –¢–æ–ø-20 —Ö—ç—à—Ç–µ–≥–æ–≤\n",
    "* –•—ç—à—Ç–µ–≥–∏ —Å–æ–±—Ä–∞–Ω—ã –ø–æ–¥ —Ç—ç–≥–æ–º 'entities' --> 'hashtags' --> 'text'.\n",
    "* –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–ª—é—á–∏ 'hashtags' = []. –ò—Ö –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get('entities') is not None:\n",
    "        hashtags_in_one_tweet = tweet['entities'].get('hashtags')\n",
    "        if hashtags_in_one_tweet is not None and hashtags_in_one_tweet != []:\n",
    "            for hashtags in hashtags_in_one_tweet:\n",
    "                if hashtags.get('text') is not None:\n",
    "                    tag = hashtags.get('text')\n",
    "                    tags.append(tag)\n",
    "counter_of_tags = Counter(tags)\n",
    "top_tags = counter_of_tags.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–ø-20 —Ö—ç—à—Ç–µ–≥–æ–≤:\n",
      "BTS\n",
      "Î∞©ÌÉÑÏÜåÎÖÑÎã®\n",
      "AMAs\n",
      "‰∫∫Ê∞óÊäïÁ•®„Ç¨„ÉÅ„É£\n",
      "ÌÉúÌòï\n",
      "Î∑î\n",
      "BTSinChicago\n",
      "BTSLoveYourselfTour\n",
      "Ïò§ÎäòÏùòÎ∞©ÌÉÑ\n",
      "PledgeForSwachhBharat\n",
      "MPN\n",
      "PCAs\n",
      "V\n",
      "ÏãúÏπ¥Í≥†1ÌöåÏ∞®Í≥µÏó∞\n",
      "‡πÄ‡∏õ‡πä‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡πÇ‡∏ä‡∏Ñ\n",
      "JIMIN\n",
      "running\n",
      "NCT\n",
      "ÏßÄÎØº\n",
      "WajahmuPlastik\n"
     ]
    }
   ],
   "source": [
    "print('–¢–æ–ø-20 —Ö—ç—à—Ç–µ–≥–æ–≤:')\n",
    "for tag in top_tags:\n",
    "    the_tag = tag[0]\n",
    "    print(the_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤ (–Ω–µ —Ä–µ—Ç–≤–∏—Ç–æ–≤) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ (—É–±—Ä–∞—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É) –∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å\n",
    "* –¢—ç–≥ —Ç–µ–∫—Å—Ç–∞ —Ç–≤–∏—Ç–∞ - 'text'.\n",
    "* –í—Å–µ –ª–∏—à–Ω–∏–µ –∑–Ω–∞–∫–∏ —É–±–∏—Ä–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é strip.\n",
    "* –¢–µ–∫—Å—Ç –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Å –ø–æ–º–æ—â—å—é lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 —Å–∞–º—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Å–ª–æ–≤ –≤ —Ç–≤–∏—Ç–∞—Ö –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ:\n",
      "the\n",
      "to\n",
      "a\n",
      "i\n",
      "and\n",
      "is\n",
      "you\n",
      "of\n",
      "for\n",
      "it\n",
      "in\n",
      "that\n",
      "this\n",
      "my\n",
      "me\n",
      "be\n",
      "on\n",
      "are\n",
      "what\n",
      "so\n",
      "with\n",
      "have\n",
      "your\n",
      "not\n",
      "more\n",
      "but\n",
      "at\n",
      "get\n",
      "about\n",
      "like\n",
      "just\n",
      "we\n",
      "all\n",
      "now\n",
      "was\n",
      "he\n",
      "up\n",
      "they\n",
      "if\n",
      "only\n"
     ]
    }
   ],
   "source": [
    "need_to_clean = '!\"#$%&\\'-()*+,./:;<=>?@[\\\\]^_`{|}~¬´¬ª‚Äî1234567890‚Ä¶'\n",
    "words = []\n",
    "for tweet in twitter:\n",
    "    if 'retweeted_status' not in tweet:\n",
    "        if tweet.get('lang') == 'en':\n",
    "            text = tweet.get('text').lower().split()\n",
    "            for word in text:\n",
    "                cleaned_text = word.strip(need_to_clean)\n",
    "                if cleaned_text != '':\n",
    "                    words.append(cleaned_text)\n",
    "counter_of_words = Counter(words).most_common(40)\n",
    "print('40 —Å–∞–º—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Å–ª–æ–≤ –≤ —Ç–≤–∏—Ç–∞—Ö –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ:')\n",
    "for word in counter_of_words:\n",
    "    one_word = word[0]\n",
    "    print(one_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) –ù–∞–π—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ (—Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤) —É –∞–≤—Ç–æ—Ä–æ–≤ —Ç–≤–∏—Ç–æ–≤ –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø-10.\n",
    "* –¢—ç–≥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - 'user'.\n",
    "* –¢—ç–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ - 'followers_count'.\n",
    "* –í —Å–ª–æ–≤–∞—Ä–µ auth_foll –∫–ª—é—á–∏ - –∞–≤—Ç–æ—Ä—ã, –∞ –∑–Ω–∞—á–µ–Ω–∏—è - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ö –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_foll = {}\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get('user') is not None:\n",
    "        name = tweet['user'].get('name')\n",
    "        if tweet['user'].get('followers_count') is not None:\n",
    "            auth_foll[name] = tweet['user'].get('followers_count')\n",
    "\n",
    "counter_of_authors = Counter(auth_foll)\n",
    "top_authorth = counter_of_authors.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–ø-10 –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ö –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤:\n",
      "Filosof√≠a‚ôï\t2521403\n",
      "FITNESS Magazine\t1491309\n",
      "malaysiakini.com\t1206759\n",
      "NYT Science\t1137374\n",
      "Gram√°tica\t625463\n",
      "TGRT Haber\t392472\n",
      "The Sun Football ‚öΩ\t383698\n",
      "Melbourne, Australia\t374222\n",
      "Roznama Express\t318189\n",
      "üíû ·É™≈≥‡Ωû…†…õ‡Ωû·É™∆°∆°…†ƒ±…õ üíû\t311319\n"
     ]
    }
   ],
   "source": [
    "print('–¢–æ–ø-10 –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ö –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤:')\n",
    "for auth_and_foll in top_authorth:\n",
    "    author = auth_and_foll[0]\n",
    "    followers = auth_and_foll[1]\n",
    "    print(author + \"\\t\" + str(followers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) –¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–≤–∏—Ç–∞ (–∏–∑ –∫–∞–∫–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞–ø–∏—Å–∞–Ω)\n",
    "* –¢—ç–≥ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Ç–≤–∏—Ç–∞ - 'source'.\n",
    "* –í–Ω—É—Ç—Ä–∏ —Ç—ç–≥–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Å—Å—ã–ª–∫–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–∞–º–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞. –ù–∞–∑–≤–∞–Ω–∏–µ –∏—â–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "\n",
    "for tweet in twitter:\n",
    "    if tweet.get('source') is not None:\n",
    "        source = tweet.get('source')\n",
    "        searchfor = r'\\u003ca href=\\\".*?\\\" rel=\\\"nofollow\\\"\\u003e(.*?)\\u003c'\n",
    "        clean_source = re.search(searchfor, source)\n",
    "        if clean_source is not None:\n",
    "            sources.append(clean_source.group(1))\n",
    "\n",
    "counter_of_sources = Counter(sources)\n",
    "top_sources = counter_of_sources.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–≤–∏—Ç–∞:\n",
      "Twitter for iPhone\n",
      "Twitter for Android\n",
      "Twitter Web Client\n",
      "twittbot.net\n",
      "Twitter Lite\n",
      "Twitter for iPad\n",
      "TweetDeck\n",
      "Facebook\n",
      "IFTTT\n",
      "ÿ™ÿ∑ÿ®ŸäŸÇ ŸÇÿ±ÿ¢ŸÜŸä\n"
     ]
    }
   ],
   "source": [
    "print('–¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–≤–∏—Ç–∞:')\n",
    "\n",
    "for source in top_sources:\n",
    "    the_source = source[0]\n",
    "    print(the_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–¥–∞–Ω–∏—è —Å–æ–≤–µ—Ç–æ–≤–∞–ª–∏—Å—å —Å –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–π –ú–æ—Ä–æ–∑–æ–≤–æ–π, –ú–∏–ª–æ—Å–ª–∞–≤–æ–π –û—Ä–µ—Ö–æ–≤–æ–π, –î–º–∏—Ç—Ä–∏–µ–º –°–∏–Ω–∏—Ü–∏–Ω—ã–º, –°–≤–µ—Ç–ª–∞–Ω–æ–π –ö–æ–∫–æ—Ä–µ–≤–æ–π (–ë–ö–õ181)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
